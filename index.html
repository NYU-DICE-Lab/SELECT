<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SELECT: A Large-Scale Benchmark of Data Curation Strategies for Image Recognition</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css">
    <style>
        .publication-title { font-size: 2.5rem; }
        .publication-authors { margin-bottom: 1rem; }
        .eql-cntrb { font-size: 0.8rem; }
        .publication-links { margin-top: 1rem; }
    </style>
</head>
<body>
    <section class="section hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">SELECT: A Large-Scale Benchmark of Data Curation Strategies for Image Recognition</h1>
                        
                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><a href="https://penfever.github.io/" target="_blank">Benjamin Feuer</a>*,</span>
                            <span class="author-block"><a href="https://chinmayhegde.github.io/lab/" target="_blank">Jiawei Xu</a>*,</span>
                            <span class="author-block"><a href="https://nivc.github.io/" target="_blank">Niv Cohen</a>,</span>
                            <span class="author-block"><a href="https://chinmayhegde.github.io/lab/" target="_blank">Patrick Yubeaton</a>,</span>
                            <span class="author-block"><a href="https://www.linkedin.com/in/mittalgovind" target="_blank">Govind Mittal</a>,</span>
                            <span class="author-block"><a href="https://chinmayhegde.github.io/" target="_blank">Chinmay Hegde</a></span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">New York University<br>NeurIPS 2024 (Datasets and Benchmarks)</span>
                            <span class="eql-cntrb"><br>*Indicates Equal Contribution</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <a href="https://arxiv.org/pdf/2410.05057.pdf" class="button is-normal is-rounded is-dark" target="_blank">Paper</a>
                                <a href="https://huggingface.co/collections/nyu-dice-lab/imagenet-666e885314f1c262fec84ef8" class="button is-normal is-rounded is-dark" target="_blank">Data</a>
                                <a href="https://huggingface.co/collections/nyu-dice-lab/select-baselines-666e8963b955b0e655b62d13" class="button is-normal is-rounded is-dark" target="_blank">Models</a>
                                <a href="https://github.com/jimmyxu123/SELECT" class="button is-normal is-rounded is-dark" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>Data curation is the problem of how to collect and organize samples into a dataset that supports efficient learning. Despite the centrality of the task, little work has been devoted towards a large-scale, systematic comparison of various curation methods. In this work, we take steps towards a formal evaluation of data curation strategies and introduce SELECT, the first large-scale benchmark of curation strategies for image classification.</p>
                        <p>In order to generate baseline methods for the SELECT benchmark, we create a new dataset, ImageNet++, which constitutes the largest superset of ImageNet-1K to date. Our dataset extends ImageNet with 5 new training-data shifts, each approximately the size of ImageNet-1K, and each assembled using a distinct curation strategy. We evaluate our data curation baselines in two ways: (i) using each training-data shift to train identical image classification models from scratch (ii) using it to inspect a fixed pretrained self-supervised representation.</p>
                        <p>Our findings show interesting trends, particularly pertaining to recent methods for data curation such as synthetic data generation and lookup based on CLIP embeddings. We show that although these strategies are highly competitive for certain tasks, the curation strategy used to assemble the original ImageNet-1K dataset remains the gold standard. We anticipate that our benchmark can illuminate the path for new methods to further reduce the gap. We release our checkpoints, code, documentation, and a link to our dataset at <a href="https://github.com/jimmyxu123/SELECT">https://github.com/jimmyxu123/SELECT</a>.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section className="section">
        <div className="container is-max-desktop">
            <div className="columns is-centered has-text-centered">
                <div className="column is-four-fifths">
                    <h5 className="subtitle is-5">June 12, 2024</h5>
                    <div className="content has-text-justified">
                        <p className="c18"><span className="c9">Introducing </span><strong>SELECT</strong><span className="c0">: A Large-Scale Benchmark for Data Curation in Image Classification</span>
                        </p>
                        <p className="c18"><span className="c9">Data curation is a critical yet often overlooked aspect of machine learning. The process of collecting, organizing, and preparing datasets significantly impacts model performance, but until now, there hasn't been a comprehensive way to evaluate different curation strategies. Enter SELECT, a new large-scale benchmark designed to systematically compare various data curation methods for image classification tasks.</span>
                        </p>
                    </div>
                </div>
            </div>
        </div>
      </section>
      
      <section className="section">
        <div className="container is-max-desktop">
            <div className="columns is-centered has-text-centered">
                <div className="column is-four-fifths">
                    <h2 className="title is-3">What is SELECT?</h2>
                    <div className="content has-text-justified">
                        <p className="c18">
                            <span className="c0">SELECT (Systematic Evaluation of Large-scale Efficient Curation Techniques) is a benchmark that allows researchers to assess the effectiveness of different data curation strategies. It provides a standardized way to measure how well curated datasets perform across a range of metrics, including: </span>
                        </p>
                        <ol className="c28 lst-kix_st344of4rgcu-0 start" start="1">
                            <li className="c18 c29 li-bullet-0">
                                <span className="c0">Base accuracy on ImageNet validation set </span>
                            </li>
                            <li className="c18 c29 li-bullet-0"><span className="c0">Out-of-distribution (OOD) robustness </span></li>
                            <li className="c18 c29 li-bullet-0"><span className="c0">Performance on downstream tasks </span></li>
                            <li className="c18 c29 li-bullet-0"><span className="c0">Effectiveness for self-supervised learning </span></li>
                        </ol>
                        <p className="c10"><span className="c0"></span></p>
                        <p className="c18"><span className="c9">The benchmark also includes several analytical metrics to help understand dataset properties without requiring model training, such as class imbalance measures and image quality scores.</span></p>
                        <img src="static/images/select.jpg" alt="SELECT benchmark" />
                    </div>
                </div>
            </div>
        </div>
      </section>
      
      
      <section class="hero is-small">
        <div class="hero-body">
          <div class="container has-text-centered">
            <img src="static/images/imagenetpp.jpg" alt="Static Image Description" />
            <!-- <h2 class="subtitle">
              Static image description.
            </h2> -->
          </div>
        </div>
      </section>
      
      
      <section class="hero is-small">
        <div class="hero-body">
          <div class="container has-text-centered">
            <img src="static/images/data-curation-perf.png" alt="Comparative performance of data curation methods, visualized in a radar plot" />
            <!--  <h2 class="subtitle">
              Static image description.
            </h2> -->
          </div>
        </div>
      </section>

    <footer class="footer">
        <div class="content has-text-centered">
            <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>
                which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
        </div>
    </footer>
</body>
</html>